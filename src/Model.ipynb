{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "PATH  = r\"C:\\Users\\jthan\\OneDrive\\Desktop\\2023\\PP\\MNIST\"\n",
    "os.chdir(PATH)\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Invert the pixel values\n",
    "train_images = 255 - train_images\n",
    "test_images = 255 - test_images\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((train_images.shape[0], 28 * 28))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28 * 28))\n",
    "\n",
    "# one-hot encode the labels\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2645 - accuracy: 0.9179 - val_loss: 0.2125 - val_accuracy: 0.9299\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1359 - accuracy: 0.9582 - val_loss: 0.1308 - val_accuracy: 0.9581\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1024 - accuracy: 0.9675 - val_loss: 0.1029 - val_accuracy: 0.9703\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0840 - accuracy: 0.9739 - val_loss: 0.0950 - val_accuracy: 0.9693\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0716 - accuracy: 0.9777 - val_loss: 0.1170 - val_accuracy: 0.9655\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.0998 - val_accuracy: 0.9701\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0538 - accuracy: 0.9822 - val_loss: 0.0866 - val_accuracy: 0.9777\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 0.1007 - val_accuracy: 0.9723\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 0.0895 - val_accuracy: 0.9748\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.0924 - val_accuracy: 0.9743\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0924 - accuracy: 0.9743\n",
      "Test Accuracy: 97.43%\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, activation='relu', input_shape=(28*28,)),  \n",
    "     tf.keras.layers.Dense(256, activation='relu'),  \n",
    "     tf.keras.layers.Dense(10, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jthan\\OneDrive\\Desktop\\2023\\PP\\MNIST\\src\\Model.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jthan/OneDrive/Desktop/2023/PP/MNIST/src/Model.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jthan/OneDrive/Desktop/2023/PP/MNIST/src/Model.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jthan/OneDrive/Desktop/2023/PP/MNIST/src/Model.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m visualize_vector(train_images[\u001b[39m0\u001b[39;49m], train_labels[\u001b[39m0\u001b[39;49m])\n",
      "\u001b[1;32mc:\\Users\\jthan\\OneDrive\\Desktop\\2023\\PP\\MNIST\\src\\Model.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jthan/OneDrive/Desktop/2023/PP/MNIST/src/Model.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m image_2d \u001b[39m=\u001b[39m image_vector\u001b[39m.\u001b[39mreshape((\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jthan/OneDrive/Desktop/2023/PP/MNIST/src/Model.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(image_2d, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jthan/OneDrive/Desktop/2023/PP/MNIST/src/Model.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m prediction \u001b[39m!=\u001b[39;49m \u001b[39m999\u001b[39;49m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jthan/OneDrive/Desktop/2023/PP/MNIST/src/Model.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     plt\u001b[39m.\u001b[39mtitle(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPrediction: \u001b[39m\u001b[39m{\u001b[39;00mprediction\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jthan/OneDrive/Desktop/2023/PP/MNIST/src/Model.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaaUlEQVR4nO3df2xV9f3H8dfl1xXh9roO23s7atMY2BwQFn5DlB9udjQZA+sSlMSBfxCcBUcKIwJZ6H6EGojEbFWXGYPoREg2YGwQsQ5aJAyHpATGHMFRRjfaNTC4txRWAny+fxDu12sr+Lney7u3fT6Sm9Bz75v74XDSJ4d7e27AOecEAICBXtYLAAD0XEQIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY6WO9gE+7fv26zpw5o1AopEAgYL0cAIAn55xaW1tVUFCgXr1ufa7T5SJ05swZFRYWWi8DAPAFNTY2avDgwbd8TJeLUCgUknRj8Tk5OcarAQD4isfjKiwsTHw/v5WMRejll1/W2rVr1dTUpGHDhunFF1/UQw89dNu5m/8Fl5OTQ4QAIIt9npdUMvLGhM2bN2vx4sVauXKl6uvr9dBDD6m0tFSnT5/OxNMBALJUIBNX0R4/frxGjRqlV155JbHtgQce0KxZs1RVVXXL2Xg8rnA4rFgsxpkQAGQhn+/jaT8TunLlig4dOqSSkpKk7SUlJdq/f3+Hx7e3tysejyfdAAA9Q9ojdPbsWV27dk35+flJ2/Pz89Xc3Nzh8VVVVQqHw4kb74wDgJ4jYz+s+ukXpJxznb5ItXz5csViscStsbExU0sCAHQxaX933KBBg9S7d+8OZz0tLS0dzo4kKRgMKhgMpnsZAIAskPYzoX79+mn06NGqqalJ2l5TU6NJkyal++kAAFksIz8nVFFRoSeffFJjxozRxIkT9etf/1qnT5/W008/nYmnAwBkqYxEaPbs2Tp37px++tOfqqmpScOHD9fOnTtVVFSUiacDAGSpjPyc0BfBzwkBQHYz/TkhAAA+LyIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMBMH+sFAF3JtWvXvGdisVgGVpIe1dXVKc1dunTJe+b48ePeMy+99JL3zNKlS71n3n77be8ZSbrrrru8Z5577jnvmVWrVnnPdBecCQEAzBAhAICZtEeosrJSgUAg6RaJRNL9NACAbiAjrwkNGzZM7733XuLr3r17Z+JpAABZLiMR6tOnD2c/AIDbyshrQidOnFBBQYGKi4v1+OOP6+TJk5/52Pb2dsXj8aQbAKBnSHuExo8frzfeeEO7du3Sq6++qubmZk2aNEnnzp3r9PFVVVUKh8OJW2FhYbqXBADootIeodLSUj322GMaMWKEvvWtb2nHjh2SpA0bNnT6+OXLlysWiyVujY2N6V4SAKCLyvgPqw4YMEAjRozQiRMnOr0/GAwqGAxmehkAgC4o4z8n1N7ero8++kjRaDTTTwUAyDJpj9DSpUtVV1enhoYGffDBB/re976neDyuuXPnpvupAABZLu3/Hfevf/1LTzzxhM6ePat7771XEyZM0IEDB1RUVJTupwIAZLm0R2jTpk3p/i3RRZ0+fdp75sqVK94z+/fv957Zt2+f94wkXbhwwXvmd7/7XUrP1d0MHjzYe+bZZ5/1ntm6dav3TCgU8p6RpJEjR3rPTJkyJaXn6qm4dhwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYCbjH2qHrq++vj6luW9+85veM7FYLKXnwp3Vq5f/v09//vOfe88MGDDAe2bOnDneMwUFBd4zkvSlL33Je+arX/1qSs/VU3EmBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNcRRsqKipKae7LX/6y9wxX0b5h3Lhx3jOpXNF5z5493jOS1K9fP++ZJ598MqXnQs/GmRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYLmEK5ubkpza1du9Z75o9//KP3zDe+8Q3vmR/+8IfeM6lKZX01NTXeMwMHDvSe+etf/+o9I0m/+MUvUpoDfHEmBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYCTjnnPUiPikejyscDisWiyknJ8d6OUizeDzuPRMKhbxnFixY4D0jSa+99pr3zJtvvuk9M2fOHO8ZIFv4fB/nTAgAYIYIAQDMeEdo7969mjFjhgoKChQIBLRt27ak+51zqqysVEFBgfr376+pU6fq2LFj6VovAKAb8Y5QW1ubRo4cqerq6k7vX7NmjdatW6fq6modPHhQkUhEjzzyiFpbW7/wYgEA3Yv3J6uWlpaqtLS00/ucc3rxxRe1cuVKlZWVSZI2bNig/Px8bdy4MeUXiwEA3VNaXxNqaGhQc3OzSkpKEtuCwaCmTJmi/fv3dzrT3t6ueDyedAMA9AxpjVBzc7MkKT8/P2l7fn5+4r5Pq6qqUjgcTtwKCwvTuSQAQBeWkXfHBQKBpK+dcx223bR8+XLFYrHErbGxMRNLAgB0Qd6vCd1KJBKRdOOMKBqNJra3tLR0ODu6KRgMKhgMpnMZAIAskdYzoeLiYkUiEdXU1CS2XblyRXV1dZo0aVI6nwoA0A14nwldvHhRH3/8ceLrhoYGHT58WLm5ubrvvvu0ePFirV69WkOGDNGQIUO0evVq3X333VymBADQgXeEPvzwQ02bNi3xdUVFhSRp7ty5ev3117Vs2TJdvnxZzzzzjM6fP6/x48fr3XffTen6XwCA7o0LmKJb+tGPfpTS3Lp167xnpkyZ4j3z3nvvec/06sVVtpAduIApACArECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwExaP1kV6CpWrVqV0tyhQ4e8Z+rq6rxnUrmKdklJifcM0NVxJgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmAk455z1Ij4pHo8rHA4rFospJyfHejnoYf7xj394z4waNcp75p577vGemTZtmvfMmDFjvGckqby83HsmEAik9Fzofny+j3MmBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY6WO9AKAruf/++71nXn/9de+Zp556ynvmzTffvCMzktTW1uY98/3vf997JhqNes+ge+FMCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwE3DOOetFfFI8Hlc4HFYsFlNOTo71coCMOHr0qPfMkiVLvGf+9Kc/ec+kasGCBd4zK1as8J4ZPHiw9wzuLJ/v45wJAQDMECEAgBnvCO3du1czZsxQQUGBAoGAtm3blnT/vHnzFAgEkm4TJkxI13oBAN2Id4Ta2to0cuRIVVdXf+Zjpk+frqampsRt586dX2iRAIDuyfuTVUtLS1VaWnrLxwSDQUUikZQXBQDoGTLymlBtba3y8vI0dOhQzZ8/Xy0tLZ/52Pb2dsXj8aQbAKBnSHuESktL9dZbb2n37t164YUXdPDgQT388MNqb2/v9PFVVVUKh8OJW2FhYbqXBADoorz/O+52Zs+enfj18OHDNWbMGBUVFWnHjh0qKyvr8Pjly5eroqIi8XU8HidEANBDpD1CnxaNRlVUVKQTJ050en8wGFQwGMz0MgAAXVDGf07o3LlzamxsVDQazfRTAQCyjPeZ0MWLF/Xxxx8nvm5oaNDhw4eVm5ur3NxcVVZW6rHHHlM0GtWpU6e0YsUKDRo0SI8++mhaFw4AyH7eEfrwww81bdq0xNc3X8+ZO3euXnnlFR09elRvvPGGLly4oGg0qmnTpmnz5s0KhULpWzUAoFvgAqZAlrhw4YL3zB/+8IeUnuupp57ynknlW8nDDz/sPVNTU+M9gzuLC5gCALICEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHAVbQAdpPJpx1evXvWe6dPH/8Odd+3a5T0zdepU7xmkjqtoAwCyAhECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABgxv/qgQC+sCNHjnjP/Pa3v/WeOXjwoPeMlNrFSFPx9a9/3Xtm8uTJGVgJrHAmBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4QKmwCccP37ce+aXv/yl98zWrVu9Z5qbm71n7qTevXt7z0SjUe+ZXr34t3N3wt8mAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGC5iiy0vlwp0bN25M6bleeukl75lTp06l9Fxd2ZgxY7xnVq5c6T3z3e9+13sG3QtnQgAAM0QIAGDGK0JVVVUaO3asQqGQ8vLyNGvWrA6fv+KcU2VlpQoKCtS/f39NnTpVx44dS+uiAQDdg1eE6urqVF5ergMHDqimpkZXr15VSUmJ2traEo9Zs2aN1q1bp+rqah08eFCRSESPPPKIWltb0754AEB283pjwjvvvJP09fr165WXl6dDhw5p8uTJcs7pxRdf1MqVK1VWViZJ2rBhg/Lz87Vx40YtWLAgfSsHAGS9L/SaUCwWkyTl5uZKkhoaGtTc3KySkpLEY4LBoKZMmaL9+/d3+nu0t7crHo8n3QAAPUPKEXLOqaKiQg8++KCGDx8u6f/fSpufn5/02Pz8/M98m21VVZXC4XDiVlhYmOqSAABZJuUILVy4UEeOHNHbb7/d4b5AIJD0tXOuw7abli9frlgslrg1NjamuiQAQJZJ6YdVFy1apO3bt2vv3r0aPHhwYnskEpF044woGo0mtre0tHQ4O7opGAwqGAymsgwAQJbzOhNyzmnhwoXasmWLdu/ereLi4qT7i4uLFYlEVFNTk9h25coV1dXVadKkSelZMQCg2/A6EyovL9fGjRv1+9//XqFQKPE6TzgcVv/+/RUIBLR48WKtXr1aQ4YM0ZAhQ7R69WrdfffdmjNnTkb+AACA7OUVoVdeeUWSNHXq1KTt69ev17x58yRJy5Yt0+XLl/XMM8/o/PnzGj9+vN59912FQqG0LBgA0H0EnHPOehGfFI/HFQ6HFYvFlJOTY70c3MJ//vMf75lUrp6xaNEi75m///3v3jNd3bhx47xnli1bltJzzZw503umVy+uAoYbfL6Pc9QAAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADATEqfrIqu67///a/3zIIFC1J6rsOHD3vPnDx5MqXn6spS+cDGJUuWeM98+9vf9p7p37+/9wxwJ3EmBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4QKmd8gHH3zgPbN27Vrvmb/85S/eM//+97+9Z7q6VC/c+eyzz3rPrFixwntm4MCB3jNAd8SZEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghguY3iFbt269IzN30gMPPOA9M2PGDO+Z3r17e88sXbrUe0aS7rnnnpTmAKSGMyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwEzAOeesF/FJ8Xhc4XBYsVhMOTk51ssBAHjy+T7OmRAAwAwRAgCY8YpQVVWVxo4dq1AopLy8PM2aNUvHjx9Pesy8efMUCASSbhMmTEjrogEA3YNXhOrq6lReXq4DBw6opqZGV69eVUlJidra2pIeN336dDU1NSVuO3fuTOuiAQDdg9cnq77zzjtJX69fv155eXk6dOiQJk+enNgeDAYViUTSs0IAQLf1hV4TisVikqTc3Nyk7bW1tcrLy9PQoUM1f/58tbS0fObv0d7erng8nnQDAPQMKb9F2zmnmTNn6vz583r//fcT2zdv3qyBAweqqKhIDQ0N+vGPf6yrV6/q0KFDCgaDHX6fyspK/eQnP+mwnbdoA0B28nmLdsoRKi8v144dO7Rv3z4NHjz4Mx/X1NSkoqIibdq0SWVlZR3ub29vV3t7e9LiCwsLiRAAZCmfCHm9JnTTokWLtH37du3du/eWAZKkaDSqoqIinThxotP7g8Fgp2dIAIDuzytCzjktWrRIW7duVW1trYqLi287c+7cOTU2Nioajaa8SABA9+T1xoTy8nL95je/0caNGxUKhdTc3Kzm5mZdvnxZknTx4kUtXbpUf/7zn3Xq1CnV1tZqxowZGjRokB599NGM/AEAANnL6zWhQCDQ6fb169dr3rx5unz5smbNmqX6+npduHBB0WhU06ZN089+9jMVFhZ+rufg2nEAkN0y9prQ7XrVv39/7dq1y+e3BAD0YFw7DgBghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABgpo/1Aj7NOSdJisfjxisBAKTi5vfvm9/Pb6XLRai1tVWSVFhYaLwSAMAX0draqnA4fMvHBNznSdUddP36dZ05c0ahUEiBQCDpvng8rsLCQjU2NionJ8dohfbYDzewH25gP9zAfrihK+wH55xaW1tVUFCgXr1u/apPlzsT6tWrlwYPHnzLx+Tk5PTog+wm9sMN7Icb2A83sB9usN4PtzsDuok3JgAAzBAhAICZrIpQMBjUqlWrFAwGrZdiiv1wA/vhBvbDDeyHG7JtP3S5NyYAAHqOrDoTAgB0L0QIAGCGCAEAzBAhAICZrIrQyy+/rOLiYt11110aPXq03n//fesl3VGVlZUKBAJJt0gkYr2sjNu7d69mzJihgoICBQIBbdu2Lel+55wqKytVUFCg/v37a+rUqTp27JjNYjPodvth3rx5HY6PCRMm2Cw2Q6qqqjR27FiFQiHl5eVp1qxZOn78eNJjesLx8Hn2Q7YcD1kToc2bN2vx4sVauXKl6uvr9dBDD6m0tFSnT5+2XtodNWzYMDU1NSVuR48etV5SxrW1tWnkyJGqrq7u9P41a9Zo3bp1qq6u1sGDBxWJRPTII48krkPYXdxuP0jS9OnTk46PnTt33sEVZl5dXZ3Ky8t14MAB1dTU6OrVqyopKVFbW1viMT3hePg8+0HKkuPBZYlx48a5p59+Omnb1772Nffcc88ZrejOW7VqlRs5cqT1MkxJclu3bk18ff36dReJRNzzzz+f2Pa///3PhcNh96tf/cpghXfGp/eDc87NnTvXzZw502Q9VlpaWpwkV1dX55zrucfDp/eDc9lzPGTFmdCVK1d06NAhlZSUJG0vKSnR/v37jVZl48SJEyooKFBxcbEef/xxnTx50npJphoaGtTc3Jx0bASDQU2ZMqXHHRuSVFtbq7y8PA0dOlTz589XS0uL9ZIyKhaLSZJyc3Ml9dzj4dP74aZsOB6yIkJnz57VtWvXlJ+fn7Q9Pz9fzc3NRqu688aPH6833nhDu3bt0quvvqrm5mZNmjRJ586ds16amZt//z392JCk0tJSvfXWW9q9e7deeOEFHTx4UA8//LDa29utl5YRzjlVVFTowQcf1PDhwyX1zOOhs/0gZc/x0OWuon0rn/5oB+dch23dWWlpaeLXI0aM0MSJE3X//fdrw4YNqqioMFyZvZ5+bEjS7NmzE78ePny4xowZo6KiIu3YsUNlZWWGK8uMhQsX6siRI9q3b1+H+3rS8fBZ+yFbjoesOBMaNGiQevfu3eFfMi0tLR3+xdOTDBgwQCNGjNCJEyesl2Lm5rsDOTY6ikajKioq6pbHx6JFi7R9+3bt2bMn6aNfetrx8Fn7oTNd9XjIigj169dPo0ePVk1NTdL2mpoaTZo0yWhV9trb2/XRRx8pGo1aL8VMcXGxIpFI0rFx5coV1dXV9ehjQ5LOnTunxsbGbnV8OOe0cOFCbdmyRbt371ZxcXHS/T3leLjdfuhMlz0eDN8U4WXTpk2ub9++7rXXXnN/+9vf3OLFi92AAQPcqVOnrJd2xyxZssTV1ta6kydPugMHDrjvfOc7LhQKdft90Nra6urr6119fb2T5NatW+fq6+vdP//5T+ecc88//7wLh8Nuy5Yt7ujRo+6JJ55w0WjUxeNx45Wn1632Q2trq1uyZInbv3+/a2hocHv27HETJ050X/nKV7rVfvjBD37gwuGwq62tdU1NTYnbpUuXEo/pCcfD7fZDNh0PWRMh55x76aWXXFFRkevXr58bNWpU0tsRe4LZs2e7aDTq+vbt6woKClxZWZk7duyY9bIybs+ePU5Sh9vcuXOdczfelrtq1SoXiURcMBh0kydPdkePHrVddAbcaj9cunTJlZSUuHvvvdf17dvX3XfffW7u3Lnu9OnT1stOq87+/JLc+vXrE4/pCcfD7fZDNh0PfJQDAMBMVrwmBADonogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM/8HLV5kDSQibIMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_vector(image_vector, prediction:int = 999):\n",
    "    '''\n",
    "    Visualizes the image vector.\n",
    "    \n",
    "    Parameters:\n",
    "        image_vector (np.array): 1D array of the image.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    #assert image_vector.shape == (1,784)\n",
    "\n",
    "    image_2d = image_vector.reshape((28, 28))\n",
    "\n",
    "    plt.imshow(image_2d, cmap='gray')\n",
    "    if prediction != 999:\n",
    "        plt.title(f'Prediction: {prediction}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_vector(train_images[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_savedmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/model_savedmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
